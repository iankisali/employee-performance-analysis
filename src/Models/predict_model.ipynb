{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2f0bdb-8c43-4ad1-a541-5a5e80c44114",
   "metadata": {},
   "source": [
    "## Model Prediction and Evaluation for Employee Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea0e688-9f8d-4ecd-aa12-4943f5b63397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5ea6d7-8433-44c0-9fd9-fe08fbed9c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, processed and split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "# Importing data, Encoding and splitting data for the model\n",
    "data_path = \"/home/ec2-user/SageMaker/data/EmployeeData_Raw.csv\"\n",
    "\n",
    "try:\n",
    "    employee_df = pd.read_csv(data_path)\n",
    "    X = employee_df.drop(['PerformanceRating', 'EmpNumber'], axis=1)\n",
    "    y = employee_df['PerformanceRating']\n",
    "\n",
    "    # One hot encoding of categorical features\n",
    "    categorical_features = X.select_dtypes(include='object').columns\n",
    "    X_processed = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "\n",
    "    # Splitting data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(\"Data loaded, processed and split into training and testing sets.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {data_path} not found\")\n",
    "    X_test, y_test = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809df890-385f-4a80-99bc-27eb72024682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Logistic Regression\n",
      "Loaded Random Forest Classifier\n",
      "Loaded Light GBM Classifier\n"
     ]
    }
   ],
   "source": [
    "# Loading trained models\n",
    "trained_models = {}\n",
    "models_dir = '/home/ec2-user/SageMaker/src/Models'\n",
    "\n",
    "try:\n",
    "    trained_models['Logistic Regression'] = joblib.load(f'{models_dir}/logistic_regression_model.joblib')\n",
    "    print(\"Loaded Logistic Regression\")\n",
    "\n",
    "    trained_models['Random Forest Classifier'] = joblib.load(f'{models_dir}/random_forest_model.joblib')\n",
    "    print(\"Loaded Random Forest Classifier\")\n",
    "\n",
    "    trained_models['Light GBM Classifier'] = joblib.load(f'{models_dir}/lightgbm_model.joblib')\n",
    "    print(\"Loaded Light GBM Classifier\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading models: {e}. Model not found in '{models_dir}' directory.\")\n",
    "    trained_models = {}\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model loading: {e}\")\n",
    "    trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6960827c-6a92-4444-86a1-8a2f074c038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test dataset\n",
      "Predictions made using Logistic Regression.\n",
      "Predictions made using Random Forest Classifier.\n",
      "Predictions made using Light GBM Classifier.\n",
      "Sample prediction vs actual value of 20 values\n",
      "| Actual   | Logistic Regression Pred   | Random Forest Pred   | LightGBM Pred   |\n",
      "|:---------|:---------------------------|:---------------------|:----------------|\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 2        | 3                          | 3                    | 3               |\n",
      "| 2        | 2                          | 2                    | 2               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 2        | 3                          | 2                    | 2               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 2        | 3                          | 2                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n",
      "| 3        | 2                          | 3                    | 3               |\n",
      "| 3        | 3                          | 3                    | 3               |\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on test dataset\n",
    "if trained_models and X_test is not None:\n",
    "    print(\"Making predictions on test dataset\")\n",
    "    predictions = {}\n",
    "    for model_name, model in trained_models.items():\n",
    "        predictions[model_name] = model.predict(X_test)\n",
    "        print(f\"Predictions made using {model_name}.\")\n",
    "\n",
    "    print(\"Sample prediction vs actual value of 20 values\")\n",
    "    actual = y_test.values\n",
    "    logistic_regression_preds = predictions.get('Logistic Regression', [])\n",
    "    random_forest_preds = predictions.get('Random Forest Classifier', [])\n",
    "    lightgbm_preds = predictions.get('Light GBM Classifier', [])\n",
    "\n",
    "    sample_comparison = pd.DataFrame({\n",
    "        'Actual': actual,\n",
    "        'Logistic Regression Pred': logistic_regression_preds,\n",
    "        'Random Forest Pred': random_forest_preds,\n",
    "        'LightGBM Pred': lightgbm_preds\n",
    "    })\n",
    "    print(sample_comparison.head(20).to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "else:\n",
    "    print(\"Test data not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "675eadea-e77e-4be3-a39f-6f6daf5c8ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation on test set\n",
      "\n",
      "--- Logistic Regression Evaluation ---\n",
      "Accuracy: 0.8417\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.66      0.54      0.59        39\n",
      "           3       0.88      0.93      0.90       175\n",
      "           4       0.82      0.69      0.75        26\n",
      "\n",
      "    accuracy                           0.84       240\n",
      "   macro avg       0.78      0.72      0.75       240\n",
      "weighted avg       0.83      0.84      0.84       240\n",
      "\n",
      "\n",
      "--- Random Forest Classifier Evaluation ---\n",
      "Accuracy: 0.9167\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.91      0.79      0.85        39\n",
      "           3       0.91      0.98      0.95       175\n",
      "           4       1.00      0.65      0.79        26\n",
      "\n",
      "    accuracy                           0.92       240\n",
      "   macro avg       0.94      0.81      0.86       240\n",
      "weighted avg       0.92      0.92      0.91       240\n",
      "\n",
      "\n",
      "--- Light GBM Classifier Evaluation ---\n",
      "Accuracy: 0.9333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.91      0.79      0.85        39\n",
      "           3       0.93      0.98      0.96       175\n",
      "           4       0.95      0.81      0.88        26\n",
      "\n",
      "    accuracy                           0.93       240\n",
      "   macro avg       0.93      0.86      0.89       240\n",
      "weighted avg       0.93      0.93      0.93       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model performance\n",
    "if predictions and y_test is not None:\n",
    "    print(\"Model evaluation on test set\")\n",
    "\n",
    "    for model_name, y_pred in predictions.items():\n",
    "        print(f\"\\n--- {model_name} Evaluation ---\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"Model evaluation failed due to missing training dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb475b5-7712-4ba9-aff0-edc3927723db",
   "metadata": {},
   "source": [
    "### 4. Using the Model for Hiring\n",
    "\n",
    "The trained model can be integrated into the hiring process. When a new candidate is being considered, their relevant data points (Age, Gender, EducationBackground, etc.) would be collected. This data would then need to be preprocessed using the *exact same steps* as the training data (one-hot encoding, handling missing values if any were present, etc.). The preprocessed candidate data would then be fed into the chosen best model to obtain a predicted performance rating.\n",
    "\n",
    "This predicted rating would serve as *one* input into the hiring decision, alongside interviews, assessments, and other criteria. It should not be the sole determinant but a tool to inform the decision-makers about the candidate's potential performance based on historical employee data.\n",
    "\n",
    " **Steps for using the model in Hiring:**\n",
    " 1. Collect candidate data points corresponding to the model's features.\n",
    " 2. Preprocess the candidate data using the same steps as the training data (encoding, scaling, etc.).\n",
    " 3. Load the best performing trained model.\n",
    " 4. Use the model's `.predict()` method on the preprocessed candidate data.\n",
    " 5. Interpret the predicted performance rating as a factor in the hiring decision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
